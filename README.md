# CausalLLM - Discover cause-and-effect relationships in your data using Large Language Models and rigorous statistical methods

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![GitHub stars](https://img.shields.io/github/stars/rdmurugan/causallm.svg)](https://github.com/rdmurugan/causallm/stargazers)

CausalLLM is a library that combines traditional causal inference with modern AI to help you understand **what actually causes what** in your data.

## üöÄ Quick Start

```bash
# Clone the repository
git clone https://github.com/rdmurugan/causallm.git
cd causallm
pip install -e .
```

```python
from causallm import CausalLLM
import pandas as pd
import asyncio

# Initialize CausalLLM
causallm = CausalLLM()

# Discover causal relationships
async def main():
    result = await causallm.discover_causal_relationships(
        data=your_data,
        variables=["treatment", "outcome", "age", "income"]
    )
    
    print(f"Found {len(result.discovered_edges)} causal relationships")

# Run async function
asyncio.run(main())
```

## ‚ú® Core Features

### üß† **Hybrid Intelligence**
- **LLM-Guided Discovery**: Use GPT-4, Claude, or local models for context-aware analysis
- **Statistical Validation**: PC Algorithm, conditional independence tests, bootstrap validation
- **Domain Knowledge**: Incorporate expert knowledge and constraints

### üìä **Rigorous Methods**
- **Causal Discovery**: Automated structure learning from data
- **Do-Calculus**: Pearl's causal effect estimation
- **Counterfactuals**: "What-if" scenario generation
- **Assumption Testing**: Validate causal assumptions

### üîß **Production Ready**
- **Multiple LLM Providers**: OpenAI, Anthropic, HuggingFace, local models
- **Async Support**: Scale to large datasets
- **Extensible**: Plugin system for custom methods
- **Well-Tested**: Comprehensive test suite

## üìñ Examples

### Basic Causal Analysis
```python
from causallm import CausalLLM
import asyncio

# Initialize CausalLLM
causallm = CausalLLM()

async def analyze_data():
    # Discover causal structure
    structure = await causallm.discover_causal_relationships(
        data=df,
        variables=["marketing_spend", "sales", "seasonality", "competition"]
    )
    
    # Estimate causal effect
    effect = await causallm.estimate_causal_effect(
        data=df,
        treatment="marketing_spend",
        outcome="sales", 
        confounders=["seasonality", "competition"]
    )
    
    print(f"Causal effect: {effect.estimate:.3f} ¬± {effect.std_error:.3f}")

asyncio.run(analyze_data())
```

### Statistical Methods
```python
from causallm.core.statistical_methods import PCAlgorithm, ConditionalIndependenceTest

# Use pure statistical approach
ci_test = ConditionalIndependenceTest(method="partial_correlation")
pc = PCAlgorithm(ci_test=ci_test, max_conditioning_size=3)

# Discover causal skeleton
skeleton = pc.discover_skeleton(data)
dag = pc.orient_edges(skeleton, data)

print(f"Discovered DAG with {len(dag.edges())} causal relationships")
```

### Small Language Models
```python
# Use smaller, faster models for cost efficiency
from causallm.plugins.slm_support import create_slm_optimized_client
from causallm import CausalLLM
import asyncio

# 5-10x faster, 90% cost reduction vs GPT-4
slm_client = create_slm_optimized_client("llama2-7b")
causallm = CausalLLM(llm_client=slm_client)

# Same API, optimized prompts
async def analyze_with_slm():
    result = await causallm.discover_causal_relationships(
        data=df,
        variables=["treatment", "outcome", "confounders"]
    )
    return result

result = asyncio.run(analyze_with_slm())
```

## üèóÔ∏è Architecture

### Core Components
- **`causallm.core.causal_llm_core`**: Main CausalLLM interface and orchestration
- **`causallm.core.causal_discovery`**: PC Algorithm, LLM-guided discovery methods
- **`causallm.core.statistical_methods`**: Independence tests, PC algorithm implementation  
- **`causallm.core.dag_parser`**: Graph parsing, validation, visualization
- **`causallm.core.do_operator`**: Causal effect estimation, intervention analysis
- **`causallm.core.counterfactual_engine`**: What-if scenario generation
- **`causallm.core.llm_client`**: Multi-provider LLM integration and prompt templates

### Plugin System
- **`causallm.plugins.slm_support`**: Small Language Model optimizations and clients
- **`causallm.mcp`**: Model Context Protocol integration for enhanced LLM capabilities

### Utilities
- **`causallm.utils`**: Data utilities, logging, and validation helpers

## üì¶ Installation Options

### Basic Installation
```bash
git clone https://github.com/rdmurugan/causallm.git
cd causallm
pip install -e .
```

### With All Dependencies
```bash
git clone https://github.com/rdmurugan/causallm.git
cd causallm
pip install -e ".[full]"
```

### Development
```bash
git clone https://github.com/rdmurugan/causallm.git
cd causallm
pip install -e ".[dev]"
```

## üî¨ Use Cases

### **Healthcare & Life Sciences**
```python
import asyncio
from causallm import CausalLLM

causallm = CausalLLM()

# Clinical trial analysis
async def analyze_clinical_trial():
    result = await causallm.discover_causal_relationships(
        data=clinical_data,
        variables=["drug_dosage", "recovery_time", "age", "severity"]
    )
    return result

result = asyncio.run(analyze_clinical_trial())
```

### **Business & Marketing**
```python
import asyncio
from causallm import CausalLLM

causallm = CausalLLM()

# Marketing attribution analysis
async def analyze_marketing():
    attribution = await causallm.estimate_causal_effect(
        data=campaign_data,
        treatment="ad_spend",
        outcome="conversions",
        confounders=["seasonality", "brand_awareness"]
    )
    return attribution

result = asyncio.run(analyze_marketing())
```

### **Economics & Policy**
```python
import asyncio
from causallm import CausalLLM

causallm = CausalLLM()

# Policy intervention analysis
async def analyze_policy():
    policy_effect = await causallm.estimate_causal_effect(
        data=policy_data,
        treatment="minimum_wage_increase",
        outcome="employment_rate",
        confounders=["gdp_growth", "unemployment_rate"]
    )
    return policy_effect

result = asyncio.run(analyze_policy())
```

## üéØ Why CausalLLM?

### **Research-Backed**
Built based on decades of causal inference research (Pearl, Rubin, etc.) with modern AI enhancements.

### **Hybrid Approach** 
Combines rigorous statistical methods with LLM contextual understanding.

### **Production Ready**
- Handles datasets up to 1M+ rows
- Async processing for scalability  
- Comprehensive error handling and validation

### **Open Source**
- MIT licensed - use anywhere
- Working to involve the community (please help spread the word and be an active member to contribute)
- Transparent algorithms and methods


## üìä Performance

| Method | Accuracy* | Speed | Cost |
|--------|-----------|-------|------|
| Traditional PC | 85% | 1x | Free |
| GPT-4 Enhanced | 94% | 0.3x | $$$$ |
| **CausalLLM Hybrid** | **96%** | **0.8x** | **$$** |
| CausalLLM + SLM | 92% | 3x | $ |

*On standard causal discovery benchmarks

## üìñ Documentation

- [**Examples**](examples/) - Real-world use cases and tutorials
- [**Usage Examples**](USAGE_EXAMPLES.md) - Detailed usage patterns
- [**Contributing**](CONTRIBUTING.md) - How to contribute to the project

For detailed documentation, API references, and guides, please contact durai@infinidatum.net

## üåü Enterprise Features

Need advanced capabilities for production use? Check out [**CausalLLM Enterprise**](https://causallm.com/enterprise):

- üîí **Advanced Security**: RBAC, audit logging, compliance
- ‚ö° **Auto-Scaling**: Kubernetes-native, handles TB+ datasets  
- üìä **Advanced Monitoring**: Prometheus, Grafana, observability
- ü§ñ **MLOps Integration**: Model lifecycle, A/B testing, deployment
- ‚òÅÔ∏è **Cloud Native**: AWS, Azure, GCP integrations
- üìû **Priority Support**: SLA-backed support and training

## ü§ù Contributing

We welcome contributions from the community!

### Ways to Contribute
- üêõ **Bug reports** and feature requests
- üìù **Documentation** improvements  
- üß™ **Test cases** and examples
- üí° **New algorithms** and methods
- üåç **Community support** and tutorials

### Development Setup
```bash
git clone https://github.com/rdmurugan/causallm.git
cd causallm
pip install -e ".[dev]"
pytest tests/
```

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

## üìÑ License

MIT License - see [LICENSE](LICENSE) for details.

Free for commercial and academic use.

## üåê Community

- **GitHub Discussions**: Ask questions, share examples
- **Issues**: Report bugs, request features  
- **Discord**: [Join our community](https://discord.gg/d4zD76hb)

## üìö Citation

If you use CausalLLM in your research, please cite:

```bibtex
@software{causallm2024,
  title={CausalLLM: Open Source Causal Inference with Large Language Models},
  author={Durai Rajamanickam},
  year={2024},
  url={https://github.com/rdmurugan/causallm}
}
```

---

‚≠ê **Star the repo** if CausalLLM helps your research or business!

**Questions?** Open an issue or start a discussion. Or reach out to durai@infinidatum.net

**Need enterprise features?** reach out to durai@infinidatum.net


About the Author: 

Durai Rajamanickam is a visionary AI executive with 20+ years of leadership in data science, causal inference, and machine learning across healthcare, financial services, legal tech, and high-growth startups. He has architected enterprise AI strategies and advised Fortune 100 firms through roles at various consulting organizations.

Durai specializes in building scalable, ethical AI systems by blending GenAI, causal ML, and hybrid NLP architectures. He is the creator of CausalLLM, an open-core framework that brings counterfactual reasoning, do-calculus, and DAG-driven insights to modern LLMs.

As the author of the upcoming book "Causal Inference for Machine Learning Engineers", Durai combines academic rigor with hands-on expertise in AI-first architecture, intelligent automation, and responsible AI governance.

LinkedIn: www.linkedin.com/in/durai-rajamanickam
