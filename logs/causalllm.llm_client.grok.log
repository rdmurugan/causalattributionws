2025-08-23 13:53:52,546 - causalllm.llm_client.grok - INFO - __init__:159 - Initializing Grok client with model: grok-1
2025-08-23 13:53:52,546 - causalllm.llm_client.grok - INFO - chat:168 - Making Grok chat request with model: grok-1
2025-08-23 13:53:52,546 - causalllm.llm_client.grok - WARNING - chat:177 - Using simulated Grok response
2025-08-23 13:53:52,546 - causalllm.llm_client.grok - INFO - chat:168 - Making Grok chat request with model: gpt-4
2025-08-23 13:53:52,546 - causalllm.llm_client.grok - WARNING - chat:177 - Using simulated Grok response
2025-08-23 13:53:52,546 - causalllm.llm_client.grok - INFO - chat:168 - Making Grok chat request with model: gpt-4
2025-08-23 13:53:52,546 - causalllm.llm_client.grok - WARNING - chat:177 - Using simulated Grok response
2025-08-23 13:53:52,547 - causalllm.llm_client.grok - INFO - chat:168 - Making Grok chat request with model: gpt-4
2025-08-23 13:53:52,547 - causalllm.llm_client.grok - WARNING - chat:177 - Using simulated Grok response
2025-08-23 14:10:29,761 - causalllm.llm_client.grok - INFO - __init__:260 - Initializing Grok client (simulated)
2025-08-23 14:10:29,761 - causalllm.llm_client.grok - WARNING - __init__:264 - Using dummy Grok API key - this is a simulated client
2025-08-23 14:10:29,762 - causalllm.llm_client.grok - ERROR - chat:278 - Empty prompt provided
2025-08-23 14:10:29,762 - causalllm.llm_client.grok - ERROR - chat:282 - Invalid temperature: 3.0
2025-08-23 14:10:29,764 - causalllm.llm_client.grok - INFO - __init__:260 - Initializing Grok client (simulated)
2025-08-23 14:10:29,764 - causalllm.llm_client.grok - WARNING - __init__:264 - Using dummy Grok API key - this is a simulated client
