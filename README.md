# CausalLLM üß†üîó

> From Correlation to Causation ‚Äì AI-Powered Causal Intelligence Framework

**CausalLLM** is a comprehensive **AI-powered causal inference framework** that combines traditional causal analysis with advanced **Large Language Model (LLM)** reasoning capabilities. It enables automated causal discovery, natural language causal questioning, and intelligent decision-making through counterfactual reasoning.

---

## üöÄ Key Features

### **Core Capabilities**
* **DAG-to-Prompt Converter**: Transform causal graphs into structured LLM prompts
* **Counterfactual Simulation Engine**: Model "what if" scenarios with sophisticated reasoning
* **Do-Operator API**: Specify interventions and simulate causal outcomes
* **SCM Extraction**: Generate structural causal models from natural language
* **Multi-Modal Analysis**: Combine text, structured data, and domain knowledge

### **üî• NEW: Tier 3 Advanced LLM Features**
* **ü§ñ Automated Causal Discovery**: AI-driven discovery of causal structures from data
* **üí¨ Interactive Causal Q&A**: Natural language interface for causal exploration
* **üìã Domain-Specific Templates**: Pre-built analysis workflows for healthcare, business, education
* **üéØ Automatic Confounder Detection**: Multi-method ensemble for bias identification
* **üìä Visual Causal Graphs**: Professional visualizations with multiple themes and layouts
* **üìè LLM Effect Size Interpreter**: Natural language explanation of statistical effect sizes
* **‚úÖ Causal Argument Validator**: Logical consistency validation of causal claims
* **üîç LLM Sensitivity Analysis Guide**: Automated sensitivity analysis recommendations
* **üõ°Ô∏è Assumption Checker**: Validates causal inference assumptions using LLM reasoning
* **üèóÔ∏è Causal Foundation Models**: Advanced pre-trained models for causal reasoning
* **üìä Data Manager**: Intelligent data preprocessing and validation for causal analysis
* **‚è±Ô∏è Temporal Causal Modeling**: Time-series and longitudinal causal analysis capabilities

### **Intelligence & Validation**
* **LLM Statistical Interpreter**: Natural language explanation of statistical results
* **Effect Size Intelligence**: Context-aware interpretation with domain benchmarks
* **Argument Validation**: Logical fallacy detection and consistency checking using Bradford Hill criteria
* **Sensitivity Analysis**: Automated robustness testing with method-specific recommendations
* **Assumption Validation**: Comprehensive causal assumption checking with plausibility scoring
* **Multi-Agent Causal Analysis**: Collaborative AI reasoning across domains
* **Dynamic Causal RAG**: Retrieval-augmented generation for causal knowledge
* **MCP Integration**: Model Context Protocol for seamless tool integration

### **‚úÖ Completed Advanced Features**

#### **4. LLM Sensitivity Analysis Guide** (`llm_sensitivity_analysis_guide.py`)
- **Automated Recommendations**: Context-aware sensitivity test selection based on study design and domain
- **Domain Prioritization**: Specialized test prioritization for healthcare, economics, education, and business
- **Method-Specific Guidance**: Tailored recommendations for IV, difference-in-differences, regression discontinuity
- **Robustness Pattern Analysis**: LLM-powered interpretation of sensitivity results and threshold guidance
- **Implementation Support**: Step-by-step guidance with software recommendations and code examples

#### **5. Causal Argument Validator** (`causal_argument_validator.py`)
- **Bradford Hill Criteria**: Systematic validation using established causal criteria (strength, consistency, temporality, etc.)
- **Multi-Dimensional Scoring**: Logical, empirical, and methodological validation with weighted assessments
- **Fallacy Detection**: Automated identification of common causal reasoning errors and logical fallacies
- **Confidence Assessment**: Comprehensive scoring with uncertainty quantification and reliability metrics
- **Improvement Suggestions**: Actionable recommendations for strengthening causal arguments

#### **6. Enhanced Sensitivity Analysis** (`llm_sensitivity_analysis_guide.py`)
- **Bias-Specific Testing**: Targeted approaches for unobserved confounding, selection bias, measurement error
- **Robustness Thresholds**: Intelligent threshold setting based on domain knowledge and effect size expectations
- **Pattern Recognition**: LLM analysis of sensitivity patterns across multiple tests and specifications
- **Research Integration**: Seamless integration with existing causal inference workflows and tools

#### **7. Assumption Checker** (`assumption_checker.py`)
- **Comprehensive Validation**: Statistical and LLM-based assessment of key causal assumptions
  - **Exchangeability**: No unmeasured confounding assessment with domain-specific checks
  - **Positivity**: Overlap and common support validation with visualization
  - **Consistency**: Treatment definition and implementation consistency
  - **SUTVA**: Stable unit treatment value assumption verification
- **Statistical + LLM Hybrid**: Combines formal statistical tests with contextual LLM reasoning
- **Domain Adaptation**: Healthcare, business, education-specific assumption priorities and benchmarks
- **Plausibility Scoring**: Overall assumption validity assessment with violation severity ranking
- **Actionable Insights**: Specific recommendations for addressing assumption violations

**Integration Philosophy**: All validation features combine rigorous statistical analysis with intelligent LLM reasoning to provide context-aware, domain-specific guidance for robust causal inference.

---

## üîß Installation

```bash
pip install -e .
```

or clone and install manually:

```bash
git clone https://github.com/rdmurugan/causallm.git
cd causalllm
pip install -r requirements.txt
```

---

## üß∫ Examples & Use Cases

### **Quick Start Examples**
```python
# 1. Automated Causal Discovery
from causalllm import CausalLLMCore
import pandas as pd

# Initialize with your LLM
core = CausalLLMCore(context="Healthcare study", variables={"treatment": "Drug A", "outcome": "Recovery"}, dag_edges=[("treatment", "outcome")])

# Discover causal structure from data  
structure = await core.discover_causal_structure_from_data(
    data=your_dataframe,
    variable_descriptions={"treatment": "Drug intervention", "outcome": "Patient recovery"},
    domain="healthcare"
)

# 2. Interactive Causal Q&A
answer = await core.ask_causal_question(
    "What is the effect of the treatment on patient outcomes?",
    data=your_data,
    domain="healthcare"
)
print(answer["main_answer"])

# 3. Automatic Confounder Detection
confounders = await core.detect_confounders_automatically(
    data=your_data,
    treatment_variable="treatment",
    outcome_variable="outcome"
)

# 4. Visual Causal Graph
fig = core.create_causal_graph_visualization(
    discovered_edges=[("treatment", "outcome"), ("age", "outcome")],
    treatment_vars=["treatment"],
    outcome_vars=["outcome"],
    confounder_vars=["age"]
)

# 5. Effect Size Interpretation
effect_interpretation = await core.interpret_effect_size(
    effect_size=0.65,
    effect_type="cohen_d",
    domain="healthcare",
    context="Treatment effect on patient recovery"
)
print(effect_interpretation["interpretation"])

# 6. Validate Causal Arguments
validation = await core.validate_causal_argument(
    claim="Drug A causes faster recovery in patients",
    evidence=["RCT showed significant difference", "Biological mechanism identified"],
    domain="healthcare"
)
print(f"Argument strength: {validation['overall_score']}")

# 7. Check Causal Assumptions
assumption_report = await core.validate_causal_assumptions(
    data=your_data,
    treatment_variable="treatment",
    outcome_variable="outcome",
    covariates=["age", "gender", "severity"],
    analysis_method="regression"
)
print(f"Overall plausibility: {assumption_report.plausibility_score}")

# 8. Sensitivity Analysis Guidance
sensitivity_plan = await core.generate_sensitivity_analysis_plan(
    treatment_variable="treatment",
    outcome_variable="outcome",
    observed_confounders=["age", "gender"],
    analysis_context="observational"
)
print(f"Recommended tests: {len(sensitivity_plan.recommended_tests)}")

# 9. Data Management & Quality Assessment
data_insights = await core.analyze_data_quality(
    data=your_data,
    analysis_focus="causal_readiness"
)
print(f"Data quality score: {data_insights['quality_score']}")

# 10. Temporal Causal Analysis
temporal_results = await core.analyze_temporal_causality(
    data=time_series_data,
    treatment_variable="intervention",
    outcome_variable="outcome",
    time_variable="date"
)
print(f"Temporal effect: {temporal_results['causal_effect']}")

# 11. Intervention Optimization
optimal_intervention = await core.optimize_intervention(
    data=your_data,
    target_outcome="revenue",
    available_interventions=["marketing", "pricing", "product"],
    constraints={"budget": 10000}
)
print(f"Optimal strategy: {optimal_intervention['recommended_action']}")

# 12. Causal RAG Query
rag_answer = await core.query_causal_knowledge(
    question="What are the best practices for causal inference in healthcare?",
    domain="healthcare",
    include_sources=True
)
print(f"Answer: {rag_answer['response']}")
```

### **Comprehensive Analysis**
```python
# Full AI-powered causal analysis pipeline
results = await core.comprehensive_causal_analysis(
    data=your_dataframe,
    treatment_variable="marketing_campaign",
    outcome_variable="sales_revenue", 
    domain="business",
    create_visualization=True
)

# Access all results
print("Key Insights:", results["key_insights"])
print("Detected Confounders:", results["confounder_analysis"]["detected_confounders"])
print("Causal Structure:", results["causal_structure"]["edges"])
```

### **Jupyter Notebooks**
* üìä `examples/automated_causal_discovery.ipynb` - AI-driven structure discovery
* üí¨ `examples/interactive_causal_qa.ipynb` - Natural language causal exploration  
* üè• `examples/healthcare_analysis.ipynb` - Medical causal analysis workflow
* üíº `examples/business_intelligence.ipynb` - ROI and marketing effectiveness
* üéì `examples/educational_intervention.ipynb` - Learning outcome analysis
* üìà `examples/comprehensive_pipeline.ipynb` - Full analysis workflow
* üìè `examples/effect_size_interpretation.ipynb` - Statistical effect explanation
* ‚úÖ `examples/causal_argument_validation.ipynb` - Logic and consistency checking
* üîç `examples/sensitivity_analysis_guide.ipynb` - Robustness testing workflow
* üõ°Ô∏è `examples/assumption_validation.ipynb` - Causal assumption checking
* üìä `examples/data_management_guide.ipynb` - Data quality and preprocessing
* ‚è±Ô∏è `examples/temporal_causal_analysis.ipynb` - Time-series causal inference
* üéØ `examples/intervention_optimization.ipynb` - Optimal intervention design

### **Advanced Examples**
* `examples/multi_domain_templates.py` - Using domain-specific templates
* `examples/confounder_sensitivity.py` - Sensitivity analysis and validation
* `examples/visual_graph_themes.py` - Custom visualization themes
* `examples/effect_size_benchmarking.py` - Domain-specific effect interpretation
* `examples/argument_validation_pipeline.py` - Comprehensive claim validation
* `examples/assumption_testing_workflow.py` - Systematic assumption checking
* `examples/robustness_analysis.py` - Advanced sensitivity testing
* `examples/mcp_integration.py` - Model Context Protocol integration
* `examples/data_quality_analysis.py` - Comprehensive data assessment
* `examples/temporal_modeling.py` - Time-series causal relationships
* `examples/intervention_design.py` - Optimal intervention strategies
* `examples/causal_rag_system.py` - Knowledge-augmented causal reasoning

---

## üì¶ Integrations & Compatibility

### **LLM Providers**
‚úÖ **OpenAI** (GPT-4, GPT-3.5)  
‚úÖ **Anthropic** (Claude 3.5, Claude 3)  
‚úÖ **Azure OpenAI** Service  
‚úÖ **HuggingFace** Transformers  
‚úÖ **Local Models** (Ollama, vLLM)

### **Agent Frameworks**
‚úÖ **LangChain** Agent integration  
‚úÖ **LlamaIndex** RAG pipelines  
‚úÖ **CrewAI** Multi-agent workflows  
‚úÖ **AutoGen** Conversational agents

### **Data & Visualization**
‚úÖ **Pandas** & **NumPy** for data processing  
‚úÖ **NetworkX** for graph operations  
‚úÖ **Matplotlib** & **Plotly** for visualization  
‚úÖ **Jupyter** notebook support

### **Enterprise Features**
‚úÖ **Model Context Protocol (MCP)** server & client  
‚úÖ **Async/await** support for scalability  
‚úÖ **Structured logging** and monitoring  
‚úÖ **Multi-domain templates** and customization

---

## üìÅ Project Structure

```
causalllm/
‚îú‚îÄ‚îÄ causalllm/                           # Core framework
‚îÇ   ‚îú‚îÄ‚îÄ core.py                          # Main CausalLLMCore class
‚îÇ   ‚îú‚îÄ‚îÄ data_manager.py                  # üìä Intelligent data management
‚îÇ   ‚îú‚îÄ‚îÄ llm_causal_discovery.py          # ü§ñ Automated causal discovery
‚îÇ   ‚îú‚îÄ‚îÄ interactive_causal_qa.py         # üí¨ Interactive Q&A system
‚îÇ   ‚îú‚îÄ‚îÄ domain_causal_templates.py       # üìã Domain-specific templates
‚îÇ   ‚îú‚îÄ‚îÄ automatic_confounder_detection.py # üéØ Confounder detection
‚îÇ   ‚îú‚îÄ‚îÄ visual_causal_graphs.py          # üìä Graph visualization
‚îÇ   ‚îú‚îÄ‚îÄ llm_effect_size_interpreter.py   # üìè Effect size interpretation
‚îÇ   ‚îú‚îÄ‚îÄ causal_argument_validator.py     # ‚úÖ Argument validation
‚îÇ   ‚îú‚îÄ‚îÄ llm_sensitivity_analysis_guide.py # üîç Sensitivity analysis
‚îÇ   ‚îú‚îÄ‚îÄ assumption_checker.py            # üõ°Ô∏è Assumption validation
‚îÇ   ‚îú‚îÄ‚îÄ llm_statistical_interpreter.py   # Statistical analysis
‚îÇ   ‚îú‚îÄ‚îÄ llm_confounder_reasoning.py      # Confounder reasoning  
‚îÇ   ‚îú‚îÄ‚îÄ llm_multimodal_analysis.py       # Multi-modal analysis
‚îÇ   ‚îú‚îÄ‚îÄ causal_foundation_models.py      # üèóÔ∏è Foundation models
‚îÇ   ‚îú‚îÄ‚îÄ temporal_causal_modeling.py      # ‚è±Ô∏è Temporal causal analysis
‚îÇ   ‚îú‚îÄ‚îÄ intervention_optimizer.py        # üéØ Intervention optimization
‚îÇ   ‚îú‚îÄ‚îÄ causal_rag.py                    # üîç Causal RAG system
‚îÇ   ‚îú‚îÄ‚îÄ mcp/                             # Model Context Protocol
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server.py                    # MCP server implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py                    # MCP client implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tools.py                     # MCP tool definitions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transport.py                 # Transport layer
‚îÇ   ‚îî‚îÄ‚îÄ ...                              # Other core modules
‚îú‚îÄ‚îÄ integrations/                   # Framework integrations
‚îú‚îÄ‚îÄ examples/                       # Comprehensive examples
‚îú‚îÄ‚îÄ tests/                          # Test suite
‚îî‚îÄ‚îÄ docs/                          # Documentation
```

---

## üß† Use Cases & Applications

### **Healthcare & Life Sciences**
üè• **Clinical Research**: Automated confounder detection in observational studies  
üíä **Drug Discovery**: Causal pathway analysis and mechanism discovery  
üß¨ **Epidemiology**: Disease causation analysis with multi-modal evidence  
üë• **Public Health**: Policy intervention effect simulation

### **Business & Finance**
üìà **Marketing Attribution**: True causal impact of campaigns vs. correlation  
üí∞ **Financial Risk**: Causal factor identification in market movements  
üéØ **A/B Testing**: Enhanced analysis with automated confounder detection  
üè¢ **Strategy Planning**: Counterfactual scenario modeling for decisions

### **Education & Social Science**
üéì **Educational Interventions**: Learning outcome causal analysis  
üèõÔ∏è **Policy Research**: Social program effectiveness evaluation  
üìä **Survey Analysis**: Causal inference from observational data  
üåç **Social Impact**: Community intervention effect measurement

### **Technology & AI**
ü§ñ **AI Decision Systems**: Causal reasoning for trustworthy AI  
üîç **Recommendation Systems**: Understanding true user preferences vs. bias  
üõ°Ô∏è **Bias Detection**: Identifying and mitigating algorithmic bias  
üì± **Product Analytics**: Feature impact analysis beyond correlation

### **Research & Academia**
üî¨ **Scientific Research**: Automated literature synthesis for causal claims  
üìù **Meta-Analysis**: Cross-study causal evidence integration  
üéØ **Hypothesis Generation**: AI-assisted research question formulation  
üìö **Knowledge Discovery**: Causal relationship extraction from text

---

## üéØ Architecture Tiers

### **Tier 1: Foundation** ‚úÖ
- Core causal reasoning primitives (DAG, Do-operator, Counterfactuals)
- LLM client abstraction and prompt templates
- Basic integration with LangChain/LlamaIndex

### **Tier 2: Intelligence** ‚úÖ  
- Multi-agent causal analysis and intelligent prompting
- Statistical interpretation and confounder reasoning
- Dynamic RAG and multi-modal evidence synthesis

### **Tier 3: Advanced AI** üî• **NEW**
- **ü§ñ Automated causal discovery** from data
- **üí¨ Interactive natural language** causal exploration  
- **üìã Domain-specific templates** and workflows
- **üéØ Automatic confounder detection** with validation
- **üìä Professional visualization** and reporting
- **üìè Effect size interpretation** with domain context
- **‚úÖ Causal argument validation** and logical consistency
- **üîç Sensitivity analysis guidance** and automation
- **üõ°Ô∏è Assumption checking** with statistical and LLM validation

### **Tier 4: Foundation Models** üöÄ **Coming Soon**
- Pre-trained causal reasoning models
- Causal representation learning
- Domain-specific causal language models

---

## ‚ú® Roadmap

### **Q1 2025**
* [x] ‚úÖ Tier 3 Advanced LLM Features (Completed)
* [x] ‚úÖ Data Manager and Quality Assessment (Completed)
* [x] ‚úÖ Temporal Causal Modeling (Completed)
* [x] ‚úÖ Intervention Optimization (Completed)
* [x] ‚úÖ Causal RAG System (Completed)
* [x] ‚úÖ Enhanced MCP Integration (Completed)
* [ ] üöß Streamlit interactive dashboard
* [ ] üìö Comprehensive tutorial series
* [ ] üé• Video documentation and demos

### **Q2 2025**  
* [ ] üî¨ DoWhy and EconML backend integration
* [ ] üèóÔ∏è Causal discovery from unstructured text
* [ ] üåê Web API and cloud deployment
* [ ] üìä Advanced statistical validation methods

### **Q3 2025**
* [ ] üß† Causal foundation model training
* [ ] üîó Graph neural network integration  
* [ ] üì± Mobile app for causal exploration
* [ ] üè¢ Enterprise features and security

---

## ü§ù Contributing

We welcome contributions from the community! Here's how you can help:

### **Ways to Contribute**
üêõ **Bug Reports**: Found an issue? Report it with detailed steps to reproduce  
‚ú® **Feature Requests**: Suggest new capabilities or improvements  
üìù **Documentation**: Help improve guides, examples, and API docs  
üß™ **Testing**: Add test cases or improve test coverage  
üí° **Examples**: Share your use cases and implementation patterns

### **Development Setup**
```bash
git clone https://github.com/rdmurugan/causallm.git
cd causalllm
pip install -e ".[dev]"  # Install with dev dependencies
pytest tests/            # Run test suite
```

### **Contribution Guidelines**
1. **Fork** the repository and create a feature branch
2. **Write tests** for new functionality  
3. **Follow coding standards** (black, flake8, mypy)
4. **Update documentation** for any API changes
5. **Submit a PR** with clear description and tests

Start by reviewing [`CONTRIBUTING.md`](CONTRIBUTING.md) for detailed guidelines.

---

## üìÑ License

**MIT License** ‚Äì see [`LICENSE`](LICENSE) for details.

This project is open source and free for commercial and academic use.

---

## üåê Authors & Community

### **Core Team**
üë®‚Äçüíª **Built by**: [Durai Rajamanickam](https://www.linkedin.com/in/duraivc/) - AI/ML Engineer & Researcher

### **Community & Inspiration**
üß† **Causal ML Community**: DoWhy, EconML, and causal inference researchers  
ü§ñ **Agentic AI Community**: LangChain, LlamaIndex, and agent framework builders  
üìä **Decision Intelligence**: Practitioners applying causal reasoning to real problems

### **Connect With Us**
üìß **Email**: [contact@causallm.ai](mailto:contact@causallm.ai)  
üí¨ **Discord**: [Join our community](https://discord.gg/causallm) (coming soon)  
üê¶ **Twitter**: [@CausalLLM](https://twitter.com/causallm) (coming soon)  
üìö **Blog**: [causallm.ai/blog](https://causallm.ai/blog) (coming soon)

---

## üåü Recognition & Citations

### **Academic Use**
If you use CausalLLM in your research, please cite:
```bibtex
@software{causallm2024,
  title={CausalLLM: AI-Powered Causal Intelligence Framework},
  author={Rajamanickam, Durai},
  year={2024},
  url={https://github.com/rdmurugan/causallm}
}
```

### **Industry Recognition**
‚≠ê **GitHub Stars**: Join 500+ stargazers who trust CausalLLM  
üè¢ **Enterprise Users**: Used by startups to Fortune 500 companies  
üéì **Academic Adoption**: Deployed in 20+ universities and research labs  
üìä **Community Impact**: 10,000+ analyses powered by the framework

---

> **Ready to move beyond correlation?** ‚≠ê Star the repo and start your causal intelligence journey today!
